<!DOCTYPE html>
<html lang="en-us">
  <head>
    <title>Common Voice Armenia: Frequently Asked Questions | Elizabeth&#39;s Blog</title>

    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">    
<meta name="viewport" content="width=device-width,minimum-scale=1">
<meta name="description" content="Common Voice Armenia was launched in May 2021. Here contains some helpful context on what it is and how you can help.">
<meta name="generator" content="Hugo 0.80.0" />


  <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">


<link rel="stylesheet" href="/css/style.css">
<link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon" />








  </head>

  <body>
    <nav class="navigation">
	
		<a href="/"> <span class="arrow">‚Üê</span>Home</a>
	
	<a href="/posts">Archive</a>
	<a href="/tags">Tags</a>
	<a href="/about">About</a>

	

	
</nav>


    <main class="main">
      

<section id="single">
    <h1 class="title">Common Voice Armenia: Frequently Asked Questions</h1>

    <div class="tip">
        <span>
          Jun 21, 2021 00:00
        </span>
        <span class="split">
          ¬∑
        </span>
        <span>
          
            1304 words
          
        </span>
        <span class="split">
          ¬∑
        </span>
        <span>
          7 minute read
        </span>
    </div>

    <div class="content">
      <p><em>Common Voice Armenia was launched in May 2021. This post contains some context on what it is and how you can help.</em></p>
<h1 id="what-is-common-voice-armenia">What is Common Voice Armenia? <a href="#what-is-common-voice-armenia" class="anchor">üîó</a></h1><p>Common Voice Armenia is a subcommunity of <a 
    href="https://commonvoice.mozilla.org"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    Common Voice
</a>, an initiative by Mozilla Firefox to help teach machines how people speak. Common Voice invites speakers from all languages to join the community and provides clear and strict <a 
    href="https://common-voice.github.io/community-playbook/"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    guidelines
</a> to launch a language in their platform. The wheel that keeps Common Voice spinning is the people who donate their time to accumulate large public datasets - in case with Common Voice, a collection of multi-lingual <a 
    href="https://common-voice.github.io/community-playbook/#-voice-corpus"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    voice corpora,
</a> which is already being used in academia and industry.  Naturally, <a 
    href="https://commonvoice.mozilla.org/hy-AM"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    Common Voice Armenia
</a> is responsible for managing the Armenian voice corpus.</p>
<h1 id="what-does-the-voice-corpus-look-like">What does the voice corpus look like? <a href="#what-does-the-voice-corpus-look-like" class="anchor">üîó</a></h1><p>Common Voice Armenia was launched after Mozilla released their latest dataset. Therefore, Armenian will be available after their next dataset release - mid of July 2021.  Watch out for announcements, because soon you will be able to download Armenian from their dropdown of <a 
    href="https://commonvoice.mozilla.org/en/datasets"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    available languages.
</a> The downloadable content will be in the form of audio, text, and metadata files.  The text is in sentence form, and its source (for now) is from Armenian Wikipedia.</p>
<h1 id="what-help-is-needed">What help is needed? <a href="#what-help-is-needed" class="anchor">üîó</a></h1><ul>
<li>
<p><strong>More Armenian text from <a 
    href="https://en.wikipedia.org/wiki/Public_domain"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    public domains.
</a></strong> They can be added manually in <a 
    href="https://commonvoice.mozilla.org/sentence-collector/"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    Sentence Collector.
</a></p>
</li>
<li>
<p><strong>More voice donations.</strong> Open an account through<a 
    href="https://commonvoice.mozilla.org/hy-AM"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    the app
</a> and start speaking sentences outloud into your microphone with your natural accent even if the spelling and grammar does not match your own (more to <a 
    href="#how-are-dialects-addressed-is-there-a-voice-corpus-for-each-dialect-similar-to-wikipedia"
    
    
    
>
    elaborate on dialects
</a> below).</p>
</li>
<li>
<p><strong>More validations.</strong> For quality assurance, each audio recording must be validated by other peers from our subcommunity.</p>
</li>
<li>
<p><strong>Better data representation.</strong> Related to the first bullet point, we need to diversify the content. Wikipedia text is not enough to train a machine on speech patterns because 1- it does not contain any conversational/dialogic text and  2- the miniscule Western Armenian content misrepresents the vast amount of Western Armenian text out there in the real world.</p>
</li>
</ul>
<h1 id="how-are-dialects-addressed-is-there-a-voice-corpus-for-each-dialect-similar-to-how-the-language-is-split-in-wikipedia">How are dialects addressed? Is there a voice corpus for each dialect similar to how the language is split in Wikipedia? <a href="#how-are-dialects-addressed-is-there-a-voice-corpus-for-each-dialect-similar-to-how-the-language-is-split-in-wikipedia" class="anchor">üîó</a></h1><p>Wikipedia hosts two sites for Armenian content, hy.wikipedia.org and hyw.wikipedia.org due to differences in orthography.  Prior to the launch, the main question was should we follow the same pattern with Common Voice, i.e. split the language to two datasets based on dialect? We<sup>1</sup> discussed this exhaustively through a collection of facebook posts, virtual meetups and google doc collaboration with experienced developers and linguists, including one coder who worked many years in Google Translate&rsquo;s team and a developer working directly with the Armenian Wikipedia team.</p>
<p>We decided that the <strong>language split in general is a bad idea</strong> and hence maintain <strong>one voice corpus</strong> containing both hy.wikipedia and hyw.wikipedia sentences. Why? -</p>
<ul>
<li>
<p>Splitting a language by some attribute (like dialect, accent, or geography) is an outdated approach when it comes to learning general speech.  The architecture of modern speech-to-text models makes them amenable to noise and are already being used in production (making $$) by other polyentric languages including English, Arabic, Portuguese, French, and Spanish. They each maintain one voice corpus.  The Armenian language should not be held as a special case entity as no other language is treated that way (Chinese is an exception due to their massive scale).</p>
</li>
<li>
<p>The split already hurts Western Armenian - by isolating it, we are abandoning it. The evidence is clear with Wikipedia; take a look at the volume of hy.wikipedia and hyw.wikipedia content.  The difference is embarassingly wide - hyw contains less than 10% of the number of articles of hy. Hyw&rsquo;s low content also prevents it to be used on modern language systems (<a 
    href="https://github.com/google-research/bert/blob/master/multilingual.md"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    literally happened with BERT
</a>), leaving it effectively and dangerously siloed.</p>
</li>
<li>
<p>It confuses developers and scientists outside the Armenian community when they see multiple Armenian language data sources. The confusion typically leads to either abondoning the less popular one (likely Western Armenian) or abandoning the language altogether in development or research.</p>
</li>
<li>
<p>Even Mozilla says so. They <em>encourage</em> multiple accents and dialects in their speaker pools. The more variance in speaker data, the more robust a predictive model will be in addressing idiomatic speech and corner cases.</p>
</li>
<li>
<p>In the case with automatic speech recognition, our system takes input from all forms of Armenian speech and should be able to process each correctly. In general, the burden should be on the developer to write better code that handles various incoming audio. The burden <em>should not</em> be on the user to manipulate their speech just so the model can work.</p>
</li>
</ul>
<p><sub>1 Natural Language Processing in Armenia community via Telegram and Facebook </sub></p>
<h1 id="about-the-voice-recordings----is-it-bad-if-i-stutter-or-re-read-a-few-words-what-about-background-noise">About the voice recordings &ndash; is it bad if I stutter or re-read a few words? What about background noise? <a href="#about-the-voice-recordings----is-it-bad-if-i-stutter-or-re-read-a-few-words-what-about-background-noise" class="anchor">üîó</a></h1><p>Yes. If you do one minor stutter - forgivable. More than one, please re-do the recording.  Validators should also reject recordings that contain more than one speech flaw.</p>
<p>Background noise is okay as long as your speech is intelligible by a normal listener.</p>
<h1 id="if-i-am-a-western-armenian-speaker-who-is-given-an-eastern-armenian-sentence-in-the-application-should-i-skip-it-and-vice-versa-for-eastern-armenian-speakers">If I am a Western Armenian speaker who is given an Eastern Armenian sentence in the application, should I skip it, and vice versa for Eastern Armenian speakers? <a href="#if-i-am-a-western-armenian-speaker-who-is-given-an-eastern-armenian-sentence-in-the-application-should-i-skip-it-and-vice-versa-for-eastern-armenian-speakers" class="anchor">üîó</a></h1><p>Please do not skip if you know how to read in both forms! Just read it naturally in your accent.</p>
<h1 id="are-there-any-links-to-documentation-to-get-more-information-about-common-voice-armenia">Are there any links to documentation to get more information about Common Voice Armenia? <a href="#are-there-any-links-to-documentation-to-get-more-information-about-common-voice-armenia" class="anchor">üîó</a></h1><ul>
<li><a 
    href="https://docs.google.com/document/d/18z-EHWDz7bX9rjBmaeQ00bM0JUtZYl0kXtus5pQhtSc/edit?usp=sharing"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    Google Doc about adding Armenian
</a></li>
<li><a 
    href="https://twitter.com/e_keleshian/status/1390319781258174465?s=20"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    Series of Twitter threads
</a></li>
<li><a 
    href="https://github.com/ekeleshian/wikiextractor/blob/liz-branch/extract_sentences_hy.py"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    Custom Wikipedia extraction script
</a></li>
<li><a 
    href="https://github.com/common-voice/common-voice/pull/3067"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    Github Pull Request
</a></li>
</ul>
<h1 id="what-can-i-do-with-a-mixed-dataset-if-my-demographic-is-eastern-armenian-speakers">What can I do with a mixed dataset if my demographic is Eastern Armenian speakers? <a href="#what-can-i-do-with-a-mixed-dataset-if-my-demographic-is-eastern-armenian-speakers" class="anchor">üîó</a></h1><p>There is a generalized technique being employed now in academia and industry that we should follow: bootstrap pretrained model then fine-tune with data specific to your use case.</p>
<p>That pretrained model is trained over large amounts of multi-lingual speech data to learn latent speech embeddings. Currently no open-source model has learned Armenian speech.  Common Voice Armenia intends to fix this by giving developers the resources needed to build this pretrained model.  The burden is then on the developer to find data specific to their use case for fine-tuning.</p>
<p>So to answer the question, you&rsquo;re not blocked at all by the fact that the dataset is mixed. You are better equipped than ever because now you will be able to plug in your data to modern architecture and build something deployable.  Take a look at the work being done at <a 
    href="https://discuss.huggingface.co/t/open-to-the-community-xlsr-wav2vec2-fine-tuning-week-for-low-resource-languages/4467"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    huggingface
</a> with automatic speech recognition.</p>
<h1 id="is-there-a-timeline">Is there a timeline? <a href="#is-there-a-timeline" class="anchor">üîó</a></h1><p>Kind of. Common Voice has a dataset release every six months. Our timeline can span one release cycle or multiple.  It is really up to us - what is our definition of success?</p>
<p>In <a 
    href="https://common-voice.github.io/community-playbook/"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    Mozilla&rsquo;s words,
</a> success is:</p>
<blockquote>
<ul>
<li>At least 1,000 unique speakers per language.</li>
<li>2,000 hours of voice validated to train a near-human general STT model.</li>
<li>10,000 hours of voice validated for a very high quality, general, large vocabulary, continuous speech recognition model</li>
</ul>
</blockquote>
<p>Success is taking baby steps towards building a baseline model for automatic speech recognition.  <a 
    href="https://arxiv.org/pdf/2006.11477.pdf"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    Wav2Vec2.0
</a> is very promising. It has been fine-tuned over various languages including low-resourced ones. For example, <a 
    href="https://huggingface.co/lighteternal/wav2vec2-large-xlsr-53-greek"
    
    
     
      target="_blank" 
      rel="noopener"
    
>
    huggingface
</a> deployed a Wav2Vec2.0 model fine-tuned over 365 MB of Greek speech data from Common Voice (~10 hrs). They achieved a word error rate of 10% on their test set.  You can <em>build</em> with this.</p>
<p>How soon can we get to 10 hours of validated recordings?  We currently have 18 speakers and 30 minutes of validated sentences. At this rate, we can generate about 4 hours of recordings per year. So we will have 10 hours in 2.5 years<sup>1</sup>.</p>
<p>I think we can and should do better. Given that automatic speech recognition is currently exploding especially with low-resourced languages, we need to catch up.</p>
<p><sub>1 Tech years can be treated like dog years. Basically that is a really long time.</sub></p>

    </div>

    
        <div class="tags">
            
                <a href="https://ekeleshian.github.io/tags/common-voice">Common Voice</a>
            
                <a href="https://ekeleshian.github.io/tags/speech-to-text">speech-to-text</a>
            
                <a href="https://ekeleshian.github.io/tags/automatic-speech-recognition">Automatic Speech Recognition</a>
            
                <a href="https://ekeleshian.github.io/tags/low-resourced-languages">low-resourced languages</a>
            
                <a href="https://ekeleshian.github.io/tags/open-source-software">open source software</a>
            
        </div>
    
    
    

</section>


    </main>
    
    <footer id="footer">
    
        <div id="social">


    <a class="symbol" href="https://github.com/ekeleshian" target="_blank">
        
        <svg fill="#bbbbbb" width="28" height="28"  viewBox="0 0 72 72" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    
    <title>Github</title>
    <desc>Created with Sketch.</desc>
    <defs></defs>
    <g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Social-Icons---Rounded-Black" transform="translate(-264.000000, -939.000000)">
            <g id="Github" transform="translate(264.000000, 939.000000)">
                <path d="M8,72 L64,72 C68.418278,72 72,68.418278 72,64 L72,8 C72,3.581722 68.418278,-8.11624501e-16 64,0 L8,0 C3.581722,8.11624501e-16 -5.41083001e-16,3.581722 0,8 L0,64 C5.41083001e-16,68.418278 3.581722,72 8,72 Z" id="Rounded" fill="#bbbbbb"></path>
                <path d="M35.9985,13 C22.746,13 12,23.7870921 12,37.096644 C12,47.7406712 18.876,56.7718301 28.4145,59.9584121 C29.6145,60.1797862 30.0525,59.4358488 30.0525,58.7973276 C30.0525,58.2250681 30.0315,56.7100863 30.0195,54.6996482 C23.343,56.1558981 21.9345,51.4693938 21.9345,51.4693938 C20.844,48.6864054 19.2705,47.9454799 19.2705,47.9454799 C17.091,46.4500754 19.4355,46.4801943 19.4355,46.4801943 C21.843,46.6503662 23.1105,48.9634994 23.1105,48.9634994 C25.2525,52.6455377 28.728,51.5823398 30.096,50.9649018 C30.3135,49.4077535 30.9345,48.3460615 31.62,47.7436831 C26.2905,47.1352808 20.688,45.0691228 20.688,35.8361671 C20.688,33.2052792 21.6225,31.0547881 23.1585,29.3696344 C22.911,28.7597262 22.0875,26.3110578 23.3925,22.9934585 C23.3925,22.9934585 25.4085,22.3459017 29.9925,25.4632101 C31.908,24.9285993 33.96,24.6620468 36.0015,24.6515052 C38.04,24.6620468 40.0935,24.9285993 42.0105,25.4632101 C46.5915,22.3459017 48.603,22.9934585 48.603,22.9934585 C49.9125,26.3110578 49.089,28.7597262 48.8415,29.3696344 C50.3805,31.0547881 51.309,33.2052792 51.309,35.8361671 C51.309,45.0917119 45.6975,47.1292571 40.3515,47.7256117 C41.2125,48.4695491 41.9805,49.9393525 41.9805,52.1877301 C41.9805,55.4089489 41.9505,58.0067059 41.9505,58.7973276 C41.9505,59.4418726 42.3825,60.1918338 43.6005,59.9554002 C53.13,56.7627944 60,47.7376593 60,37.096644 C60,23.7870921 49.254,13 35.9985,13" fill="#FFFFFF"></path>
            </g>
        </g>
    </g>
</svg>
    </a>

    <a class="symbol" href="https://twitter.com/e_keleshian" target="_blank">
        
        <svg fill="#bbbbbb" width="28" height="28" version="1.1" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 width="438.536px" height="438.536px" viewBox="0 0 438.536 438.536" style="enable-background:new 0 0 438.536 438.536;"
	 xml:space="preserve">
<g>
	<path d="M414.41,24.123C398.333,8.042,378.963,0,356.315,0H82.228C59.58,0,40.21,8.042,24.126,24.123
		C8.045,40.207,0.003,59.576,0.003,82.225v274.084c0,22.647,8.042,42.018,24.123,58.102c16.084,16.084,35.454,24.126,58.102,24.126
		h274.084c22.648,0,42.018-8.042,58.095-24.126c16.084-16.084,24.126-35.454,24.126-58.102V82.225
		C438.532,59.576,430.49,40.204,414.41,24.123z M335.471,168.735c0.191,1.713,0.288,4.278,0.288,7.71
		c0,15.989-2.334,32.025-6.995,48.104c-4.661,16.087-11.8,31.504-21.416,46.254c-9.606,14.749-21.074,27.791-34.396,39.115
		c-13.325,11.32-29.311,20.365-47.968,27.117c-18.648,6.762-38.637,10.143-59.953,10.143c-33.116,0-63.76-8.952-91.931-26.836
		c4.568,0.568,9.329,0.855,14.275,0.855c27.6,0,52.439-8.565,74.519-25.7c-12.941-0.185-24.506-4.179-34.688-11.991
		c-10.185-7.803-17.273-17.699-21.271-29.691c4.947,0.76,8.658,1.137,11.132,1.137c4.187,0,9.042-0.76,14.56-2.279
		c-13.894-2.669-25.598-9.562-35.115-20.697c-9.519-11.136-14.277-23.84-14.277-38.114v-0.571
		c10.085,4.755,19.602,7.229,28.549,7.422c-17.321-11.613-25.981-28.265-25.981-49.963c0-10.66,2.758-20.747,8.278-30.264
		c15.035,18.464,33.311,33.213,54.816,44.252c21.507,11.038,44.54,17.227,69.092,18.558c-0.95-3.616-1.427-8.186-1.427-13.704
		c0-16.562,5.853-30.692,17.56-42.399c11.703-11.706,25.837-17.561,42.394-17.561c17.515,0,32.079,6.283,43.688,18.846
		c13.134-2.474,25.892-7.33,38.26-14.56c-4.757,14.652-13.613,25.788-26.55,33.402c12.368-1.716,23.88-4.95,34.537-9.708
		C357.458,149.793,347.462,160.166,335.471,168.735z"/>
</g>
</svg>

    </a>


</div>

    

    <p class="copyright">
    
       ¬© Copyright 
       2021 
       <span class="split">
        <svg fill="#bbbbbb" width="15" height="15" version="1.1" id="heart-15" xmlns="http://www.w3.org/2000/svg" width="15px" height="15px" viewBox="0 0 15 15">
  <path d="M13.91,6.75c-1.17,2.25-4.3,5.31-6.07,6.94c-0.1903,0.1718-0.4797,0.1718-0.67,0C5.39,12.06,2.26,9,1.09,6.75&#xA;&#x9;C-1.48,1.8,5-1.5,7.5,3.45C10-1.5,16.48,1.8,13.91,6.75z"/>
</svg>
       </span>
       Elizabeth Keleshian
    
    </p>
    <p class="powerby">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
</footer>

  </body>
</html>
